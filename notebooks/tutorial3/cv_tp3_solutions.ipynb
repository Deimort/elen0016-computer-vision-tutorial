{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision - Tutorial 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical session, we will use the `opencv` library to perform thresholding, filtering, mathematical morphology and image segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from ipywidgets import interact\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def getRandomColorMap(num_colors, bg_color=1):\n",
    "    colors = np.random.rand(num_colors, 3) * 0.75\n",
    "    colors[0, :] = bg_color\n",
    "    colors = tuple(map(tuple, colors))\n",
    "\n",
    "    labelColorMap = LinearSegmentedColormap.from_list('labelColorMap', colors, N=num_colors)\n",
    "\n",
    "    return labelColorMap\n",
    "\n",
    "def multiplot(lines, rows, images, cmap, title, vmin=None, vmax=None):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    for i in np.arange(lines*rows):\n",
    "        \n",
    "        plt.subplot(lines, rows, i+1)\n",
    "        plt.imshow(images[i], cmap=cmap[i], vmax=vmax)\n",
    "        plt.title(title[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute and display the histogram of a grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cameraman_gray = cv2.imread('../Images/cameraman.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(cameraman_gray, cmap=cm.gray)\n",
    "plt.show()\n",
    "\n",
    "hist_np, bins = np.histogram(cameraman_gray.ravel(), 256, [0,256])\n",
    "\n",
    "hist_cv = cv2.calcHist([cameraman_gray], [0], None, [256], [0,256])\n",
    "\n",
    "plt.hist(cameraman_gray.ravel(), bins=256, range=(0,255))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic thresholding with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraman_threshold = cameraman_gray > 127\n",
    "\n",
    "plt.imshow(cameraman_threshold, cmap=cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thresholding with OpenCV\n",
    "Determine the v1 and v2 values for the following threshold types:  \n",
    "cv.THRESH_BINARY\n",
    "$$\\text{th_image}(x,y)=\\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  255 & \\text{if img$(x,y)$ > thresh}\\\\\n",
    "                  0 & \\text{otherwise}\n",
    "                \\end{array}\n",
    "              \\right.\n",
    "$$\n",
    "\n",
    "cv.THRESH_BINARY_INV\n",
    "$$\\text{th_image}(x,y)=\\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  0 & \\text{if img$(x,y)$ > thresh}\\\\\n",
    "                  255 & \\text{otherwise}\n",
    "                \\end{array}\n",
    "              \\right.\n",
    "$$\n",
    "\n",
    "cv.THRESH_TRUNC\n",
    "$$\\text{th_image}(x,y)=\\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  \\texttt{thresh} & \\text{if img$(x,y)$ > thresh}\\\\\n",
    "                  \\texttt{img}(x,y) & \\text{otherwise}\n",
    "                \\end{array}\n",
    "              \\right.\n",
    "$$\n",
    "\n",
    "cv.THRESH_TO_ZERO\n",
    "$$\\text{th_image}(x,y)=\\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  \\texttt{img}(x,y) & \\text{if img$(x,y)$ > thresh}\\\\\n",
    "                  \\texttt{0} & \\text{otherwise}\n",
    "                \\end{array}\n",
    "              \\right.\n",
    "$$\n",
    "\n",
    "cv.THRESH_TO_ZERO_INV\n",
    "$$\\text{th_image}(x,y)=\\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  \\texttt{0} & \\text{if img$(x,y)$ > thresh}\\\\\n",
    "                  \\texttt{img}(x,y) & \\text{otherwise}\n",
    "                \\end{array}\n",
    "              \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = cv2.imread('../Images/gradient.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "value = 127\n",
    "\n",
    "ret, thresh1 = cv2.threshold(grad, value, 255, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold(grad, value, 255, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold(grad, value, 255, cv2.THRESH_TRUNC)\n",
    "ret, thresh4 = cv2.threshold(grad, value, 255, cv2.THRESH_TOZERO)\n",
    "ret, thresh5 = cv2.threshold(grad, value, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "multiplot(2, 3,\n",
    "         (grad, thresh1, thresh2, thresh3, thresh4, thresh5),\n",
    "         (cm.gray, cm.gray, cm.gray, cm.gray, cm.gray, cm.gray),\n",
    "         ('Original Image', 'THRESH_BINARY', 'THRESH_BINARY_INV',\n",
    "          'THRESH_TRUNC', 'THRESH_TOZERO', 'THRESH_TOZERO_INV'), vmax=255, vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 127\n",
    "\n",
    "ret, thresh1 = cv2.threshold(cameraman_gray, value, 255, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold(cameraman_gray, value, 255, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold(cameraman_gray, value, 255, cv2.THRESH_TRUNC)\n",
    "ret, thresh4 = cv2.threshold(cameraman_gray, value, 255, cv2.THRESH_TOZERO)\n",
    "ret, thresh5 = cv2.threshold(cameraman_gray, value, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "multiplot(2, 3,\n",
    "         (cameraman_gray, thresh1, thresh2, thresh3, thresh4, thresh5),\n",
    "         (cm.gray, cm.gray, cm.gray, cm.gray, cm.gray, cm.gray),\n",
    "         ('Original Image', 'THRESH_BINARY', 'THRESH_BINARY_INV',\n",
    "          'THRESH_TRUNC', 'THRESH_TOZERO', 'THRESH_TOZERO_INV'), vmax=255, vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otsu's thresholding\n",
    "In the previous examples, we had to chose the threshold value. We can use Otsu's algorithm to determine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rice = cv2.imread('../Images/rice.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.hist(rice.ravel(), bins=256, range=(0,255))\n",
    "plt.show()\n",
    "\n",
    "ret, thresh1 = cv2.threshold(rice, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "ret, otsu = cv2.threshold(rice, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "multiplot(1, 3,\n",
    "         (rice, thresh1, otsu),\n",
    "         (cm.gray, cm.gray, cm.gray),\n",
    "         ('Original Image', 'THRESH_BINARY', 'THRESH_BINARY + OTSU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otsu's algorithm by parts\n",
    "You can fine-tune the result by applying this algorithm on the different parts of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "h = np.linspace(0, rice.shape[0], n+1).astype('int')\n",
    "out = []\n",
    "for i in range(n):\n",
    "    ret, th = cv2.threshold(rice[h[i]: h[i+1], :], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    out.append(th)\n",
    "\n",
    "out = np.concatenate(out, axis=0)\n",
    "\n",
    "multiplot(1, 3,\n",
    "         (rice, otsu, out),\n",
    "         (cm.gray, cm.gray, cm.gray),\n",
    "         ('Original Image', 'OTSU', 'OTSU BY PARTS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu_parts(img, n, direction=0):\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    if direction == 0:\n",
    "        l = img.shape[0]\n",
    "        h = np.linspace(0, l, n+1).astype('int')\n",
    "        axis = 0\n",
    "        for i in range(n):\n",
    "            ret, th = cv2.threshold(img[h[i]: h[i+1], :], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            out.append(th)\n",
    "    else:\n",
    "        l = img.shape[1]\n",
    "        h = np.linspace(0, l, n+1).astype('int')\n",
    "        axis = 1\n",
    "        for i in range(n):\n",
    "            ret, th = cv2.threshold(img[:, h[i]: h[i+1]], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            out.append(th)\n",
    "    \n",
    "    return np.concatenate(out, axis=axis)\n",
    "\n",
    "light_gradient = np.arange(start=132, stop=-133, step=-1) / 3\n",
    "non_uniform_lightning = (np.reshape(light_gradient, (265, 1))) * np.ones((1, 250), dtype=int)\n",
    "\n",
    "img_nu = np.clip(rice+non_uniform_lightning, 0, 255).astype(np.uint8)\n",
    "\n",
    "plt.hist(img_nu.ravel(), bins=256, range=(0,255))\n",
    "\n",
    "ret, otsu = cv2.threshold(img_nu, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "otsu_p = otsu_parts(img_nu, 5, 0)\n",
    "\n",
    "multiplot(2, 2,\n",
    "         (rice, non_uniform_lightning, otsu, otsu_p),\n",
    "         (cm.gray, cm.gray, cm.gray, cm.gray),\n",
    "         ('Original Image', 'Non-uniform lightning', 'OTSU', 'OTSU BY PARTS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = cv2.imread('../Images/Pattern_inspection2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "gaussian_noise = np.zeros_like(pattern, dtype=float)\n",
    "mean = 0.\n",
    "std = 10.\n",
    "cv2.randn(gaussian_noise, mean, std)\n",
    "\n",
    "pattern_noisy = np.clip(pattern+gaussian_noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "multiplot(1, 2,\n",
    "         (pattern, pattern_noisy),\n",
    "         (cm.gray, cm.gray),\n",
    "         ('Original image', 'Gaussian noise'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniform, Gaussian and bilateral filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_noisy_uniform_blur = cv2.blur(pattern_noisy, (7, 7))\n",
    "pattern_noisy_gaussian_blur = cv2.GaussianBlur(pattern_noisy, (7, 7), 0)\n",
    "pattern_noisy_bilateral = cv2.bilateralFilter(pattern_noisy, -1, 25, 11)\n",
    "\n",
    "multiplot(2, 2,\n",
    "         (pattern, pattern_noisy_uniform_blur, pattern_noisy_gaussian_blur, pattern_noisy_bilateral),\n",
    "         (cm.gray, cm.gray, cm.gray, cm.gray),\n",
    "         ('Original image', 'Uniform blur', 'Gaussian blur', 'Bilateral filtering'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salt and pepper noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_pepper_noise = np.zeros_like(cameraman_gray)\n",
    "cv2.randu(salt_pepper_noise, 0, 255)\n",
    "cameraman_noisy = np.where(salt_pepper_noise < 10, 0, np.where(salt_pepper_noise > 240, 255, cameraman_gray))\n",
    "\n",
    "multiplot(1, 2,\n",
    "         (cameraman_gray, cameraman_noisy),\n",
    "         (cm.gray, cm.gray),\n",
    "         ('Original image', 'Salt and pepper noise'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraman_noisy_uniform_blur = cv2.blur(cameraman_noisy, (7, 7))\n",
    "cameraman_noisy_gaussian_blur = cv2.GaussianBlur(cameraman_noisy, (7, 7), 0)\n",
    "cameraman_noisy_bilateral = cv2.bilateralFilter(cameraman_noisy, -1, 25, 11)\n",
    "\n",
    "multiplot(2, 2,\n",
    "         (cameraman_gray, cameraman_noisy_uniform_blur, cameraman_noisy_gaussian_blur, cameraman_noisy_bilateral),\n",
    "         (cm.gray, cm.gray, cm.gray, cm.gray),\n",
    "         ('Original image', 'Uniform blur', 'Gaussian blur', 'Bilateral filtering'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_pepper_noise = np.zeros_like(cameraman_gray)\n",
    "cv2.randu(salt_pepper_noise, 0, 255)\n",
    "cameraman_noisy = np.where(salt_pepper_noise < 80, 0, np.where(salt_pepper_noise > 180, 255, cameraman_gray))\n",
    "\n",
    "cameraman_noisy_median = cv2.medianBlur(cameraman_noisy, 7)\n",
    "\n",
    "multiplot(1, 3,\n",
    "         (cameraman_gray, cameraman_noisy, cameraman_noisy_median),\n",
    "         (cm.gray, cm.gray, cm.gray),\n",
    "         ('Salt and pepper noise', 'Noisy image', 'Median blur'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mathematical morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non uniform lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_uniform_lightning_like(img, weight):\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    \n",
    "    steps_y = np.arange( start=0.0, stop=1.0, step=1.0/height)\n",
    "    light_gradient_y = np.cos( ( 2.0 * ( steps_y * steps_y - steps_y) + 1.0)* np.pi)[:,np.newaxis]\n",
    "\n",
    "    steps_x = np.arange( start=0.0, stop=1.0, step=1.0/width)\n",
    "    light_gradient_x = np.cos( steps_x * np.pi)[np.newaxis,:]\n",
    "\n",
    "    return ( weight * light_gradient_y * light_gradient_x)\n",
    "\n",
    "nul = non_uniform_lightning_like(rice, 50)\n",
    "rice_nul = np.clip(rice + nul, 0, 255).astype(np.uint8)\n",
    "\n",
    "multiplot(1, 3,\n",
    "         (rice, nul, rice_nul),\n",
    "         (cm.gray, cm.gray, cm.gray),\n",
    "         ('Original Image', 'Non Uniform Lightning', 'Image + Non Uniform Lightning'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erosion and dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k = 19\n",
    "kernel = np.ones((k, k))\n",
    "\n",
    "erd = cv2.erode(rice_nul, kernel, iterations=1)\n",
    "dlt = cv2.dilate(rice_nul, kernel, iterations=1)\n",
    "\n",
    "multiplot(1, 2,\n",
    "         (erd, dlt),\n",
    "         (cm.gray, cm.gray),\n",
    "         ('Erosion', 'Dilation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_erd = cv2.GaussianBlur(erd, (k, k), 0)\n",
    "gaussian_dlt = cv2.GaussianBlur(dlt, (k, k), 0)\n",
    "\n",
    "multiplot(1, 2,\n",
    "         (gaussian_erd, gaussian_dlt),\n",
    "         (cm.gray, cm.gray),\n",
    "         ('Background', 'Foreground'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_normalize_image(img, k):\n",
    "    kernel = np.ones((k, k))\n",
    "    \n",
    "    erd = cv2.erode(img, kernel, iterations=1)\n",
    "    dlt = cv2.dilate(img, kernel, iterations=1)\n",
    "    \n",
    "    gaussian_erd = cv2.GaussianBlur(erd, (k, k), 0)\n",
    "    gaussian_dlt = cv2.GaussianBlur(dlt, (k, k), 0)\n",
    "    \n",
    "    norm_img = (img - gaussian_erd)/(gaussian_dlt - gaussian_erd + 1) * 255\n",
    "    \n",
    "    return np.clip(norm_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "rice_nul_norm = local_normalize_image(rice_nul, 19)\n",
    "\n",
    "ret, thresh1 = cv2.threshold(rice_nul, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "ret, thresh2 = cv2.threshold(rice_nul_norm, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "multiplot(2, 2,\n",
    "         (rice_nul, rice_nul_norm, thresh1, thresh2),\n",
    "         (cm.gray, cm.gray, cm.gray, cm.gray),\n",
    "         ('Image + Non Uniform Lightning', 'Uniformized Image', 'OTSU', 'OTSU + uniformized'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thresholding and connected components labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ret, thresh = cv2.threshold(pattern, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "connectivity = 4 #8\n",
    "conn_comp = cv2.connectedComponentsWithStats(thresh, connectivity, cv2.CV_32S)\n",
    "\n",
    "num_labels = conn_comp[0]\n",
    "img_labels = conn_comp[1]\n",
    "\n",
    "label_colors = getRandomColorMap(num_labels)\n",
    "\n",
    "multiplot(1, 3,\n",
    "         (pattern, thresh, img_labels),\n",
    "         (cm.gray, cm.gray, label_colors),\n",
    "         ('Original image', 'OTSU', 'Labelized'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "Closing -> Gaussian filtering -> Thresholding -> Connected components labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conn_comp_label_closing(img, k, connectivity=4):\n",
    "    kernel = np.ones((k, k))\n",
    "    \n",
    "    cls = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    gaussian_cls = cv2.GaussianBlur(cls, (k, k), 0)\n",
    "    \n",
    "    ret, thresh = cv2.threshold(gaussian_cls, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return cv2.connectedComponentsWithStats(thresh, connectivity, cv2.CV_32S), gaussian_cls, thresh\n",
    "\n",
    "conn_comp, cls, thresh = conn_comp_label_closing(pattern, 11)\n",
    "\n",
    "num_labels = conn_comp[0]\n",
    "img_labels = conn_comp[1]\n",
    "\n",
    "label_colors = getRandomColorMap(num_labels)\n",
    "\n",
    "multiplot(2, 2,\n",
    "         (pattern, cls, thresh, img_labels),\n",
    "         (cm.gray, cm.gray, cm.gray, label_colors),\n",
    "         ('Original image', 'Closing', 'OTSU', 'Labelized'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blob feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_blob_bounding_boxes(img, conn_comp):\n",
    "    num_labels = conn_comp[0]\n",
    "    stats = conn_comp[2]\n",
    "\n",
    "    img_bb = cv2.cvtColor( img, cv2.COLOR_GRAY2RGB)\n",
    "    for label in range( 1, num_labels):\n",
    "        topleft = tuple( stats[label,:2])\n",
    "        bottomright = tuple( stats[label,:2] + stats[label, 2:4])\n",
    "        cv2.rectangle( img_bb, topleft, bottomright, (255,0,0), 3)\n",
    "    \n",
    "    return img_bb\n",
    "\n",
    "\n",
    "def draw_blob_centroids(img, conn_comp):\n",
    "    num_labels = conn_comp[0]\n",
    "    centroids = conn_comp[3]\n",
    "\n",
    "    img_ctr = cv2.cvtColor( img, cv2.COLOR_GRAY2RGB)\n",
    "    for label in range( 1, num_labels):\n",
    "        centroid = tuple( centroids[label,:].astype(int))\n",
    "        cv2.circle( img_ctr, centroid, 3, (255,0,0), thickness=3)\n",
    "    \n",
    "    return img_ctr\n",
    "\n",
    "conn_comp, cls, thresh = conn_comp_label_closing(pattern, 11)\n",
    "\n",
    "num_labels = conn_comp[0]\n",
    "img_labels = conn_comp[1]\n",
    "\n",
    "label_colors = getRandomColorMap(num_labels)\n",
    "\n",
    "pattern_bb = draw_blob_bounding_boxes(pattern, conn_comp)\n",
    "\n",
    "pattern_ctr = draw_blob_centroids(pattern, conn_comp)\n",
    "\n",
    "multiplot(2, 2,\n",
    "         (pattern, img_labels, pattern_bb, pattern_ctr),\n",
    "         (cm.gray, label_colors, None, None),\n",
    "         ('Original image', 'Labelized', 'Boxes', 'Center'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rice_norm = local_normalize_image(rice, 19)\n",
    "\n",
    "ret, thresh = cv2.threshold(rice_norm, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "kernel = np.ones((3, 3))\n",
    "rice_open = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "multiplot(1, 3,\n",
    "         (rice, thresh, rice_open),\n",
    "         (cm.gray, cm.gray, cm.gray),\n",
    "         ('Original image', 'OTSU', 'Opening'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find sure background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rice_sure_bg = cv2.dilate(rice_open, kernel, iterations=3)\n",
    "\n",
    "multiplot(1, 3,\n",
    "         (rice, rice_open, rice_sure_bg),\n",
    "         (cm.gray, cm.gray, cm.gray),\n",
    "         ('Original image', 'Opening', 'Sure background'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find sure foreground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rice_dist_transform = cv2.distanceTransform(rice_open, cv2.DIST_L2, 5).astype(np.uint8)\n",
    "ret, rice_sure_fg = cv2.threshold(rice_dist_transform, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "multiplot(1, 3,\n",
    "         (rice, rice_dist_transform, rice_sure_fg),\n",
    "         (cm.gray, cm.gray, cm.gray),\n",
    "         ('Original image', 'Opening', 'Sure foreground'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find unknown region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rice_unknown = cv2.subtract(rice_sure_bg, rice_sure_fg)\n",
    "\n",
    "multiplot(1, 3,\n",
    "         (rice, rice_sure_fg, rice_unknown),\n",
    "         (cm.gray, cm.gray, cm.gray),\n",
    "         ('Original image', 'Sure foreground', 'Unknown region'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sure labelling of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, rice_sure_fg_labels = cv2.connectedComponents(rice_sure_fg)\n",
    "\n",
    "rice_sure_labels = rice_sure_fg_labels+1\n",
    "\n",
    "rice_sure_labels[rice_unknown == 255] = 0\n",
    "\n",
    "num_fg_blobs = rice_sure_fg_labels.max()\n",
    "label_fg_colors = getRandomColorMap(num_fg_blobs+1, bg_color=0)\n",
    "\n",
    "num_blobs = rice_sure_labels.max()\n",
    "label_colors = getRandomColorMap(num_blobs+1, bg_color=0)\n",
    "\n",
    "multiplot(1, 3, \n",
    "         (rice, rice_sure_fg_labels, rice_sure_labels),\n",
    "         (cm.gray, label_fg_colors, label_colors),\n",
    "         ('Original image', 'Sure foreground labels', 'Sure labels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rice_rgb = cv2.cvtColor(rice, cv2.COLOR_BGR2RGB)\n",
    "rice_labels = cv2.watershed(rice_rgb, rice_sure_labels)\n",
    "\n",
    "rice_rgb[rice_labels == -1] = [255, 0, 0]\n",
    "\n",
    "multiplot(1, 3, \n",
    "         (rice, rice_labels, rice_rgb),\n",
    "         (cm.gray, label_colors, None),\n",
    "         ('Original image', 'Segmentation', 'Contours'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
