{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision - Input/Output + Basic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first practical session, you will use the `opencv` library to handle input and output and some operations that can be applied to an image, such as taking a photo of yourself and display it in another colorspace.  \n",
    "Note that this session will cover the first part of your project as you have to record yourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageOps, ImageEnhance, Image\n",
    "from augmentation import RandAugmentation\n",
    "from ipywidgets import interact\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1:  take a photo with your webcam\n",
    "We create an object to access the webcam and we take a photo.  \n",
    "What is the format use to represent the red, blue and green channels by `opencv`. Do we need to change it to display the image with `matplotlib`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object to use the webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "# Read a frame from your webcam\n",
    "ret, frame = vid.read()\n",
    "\n",
    "# Close the webcam\n",
    "vid.release()\n",
    "\n",
    "# Convertion from BGR to RGB\n",
    "rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Save the photo\n",
    "\n",
    "cv2.imwrite('mySuperPhoto.png', frame)\n",
    "\n",
    "# Display the photo\n",
    "plt.imshow(rgb_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: change of colorspace\n",
    "Convertion of the photo in another colorspace, for example the HSV one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change of colorspace\n",
    "hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Display the result\n",
    "plt.imshow(hsv_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: apply some transformations on the image\n",
    "We can also change the properties of an image, such as its contrast, brightness, saturation, ...  \n",
    "The library `PIL` is well suited for those operations. Can you apply those transformations on an `opencv` object (array)? What kind of object do you have to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the RGB image to a PIL object\n",
    "pil_frame = Image.fromarray(rgb_frame)\n",
    "\n",
    "# Change the contrast of the image\n",
    "def contrast(v):\n",
    "    contrast = ImageEnhance.Contrast(pil_frame).enhance(v)\n",
    "\n",
    "    contrast = np.array(contrast)\n",
    "    plt.imshow(contrast)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(contrast, v=(0., 2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we apply a random augmentation to an image.  \n",
    "See `augmentation.py` for the different augmentations performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object to apply random transformation\n",
    "augmentation = RandAugmentation()\n",
    "\n",
    "# The function returns the transformed image aswell as the value applied\n",
    "img, augment = augmentation(pil_frame)\n",
    "\n",
    "print(augment)\n",
    "\n",
    "# Convert the PIL object to an array and display the result\n",
    "img = np.array(img)\n",
    "plt.subplot(1,2,1).set_title('Original')\n",
    "plt.imshow(rgb_frame)\n",
    "plt.subplot(1,2,2).set_title(augment['method'] + \" - \" + str(augment['value']))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: record a video of yourself\n",
    "Now that you can handle your webcam, you can use it to record a video of yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object to use the webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "# Frames per second of your webcam\n",
    "FPS = vid.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Length of your video in second\n",
    "VIDEO_LENGTH = 10\n",
    "\n",
    "# Size of your frames\n",
    "frame_w = int(vid.get(3))\n",
    "frame_h = int(vid.get(4))\n",
    "\n",
    "# Create the object to record a video\n",
    "rec = cv2.VideoWriter('mySuperVideo.mov', cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), FPS, (frame_w, frame_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the frames for FPS*VIDEO_LENGTH seconds\n",
    "for i in range(int(FPS*VIDEO_LENGTH)):\n",
    "\n",
    "    ret, frame = vid.read()\n",
    "    rec.write(frame)\n",
    "\n",
    "# Close the webcam and the recorder\n",
    "vid.release()\n",
    "rec.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: segmentation of a color\n",
    "Segmentation is an useful tool in computer vision. It can be used to extract pixels of the same color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "squares = cv2.imread('squares.png')\n",
    "\n",
    "# Convert from BGR to RGB\n",
    "rgb_squares = cv2.cvtColor(squares, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(rgb_squares)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the color code /!\\ BGR format\n",
    "black = np.array([0, 0, 0])\n",
    "blue = np.array([255, 0, 0])\n",
    "green = np.array([0, 255, 0])\n",
    "red = np.array([0, 0, 255])\n",
    "white = np.array([255, 255, 255])\n",
    "\n",
    "# Threshold the image to get only red color\n",
    "mask = cv2.inRange(squares, black, red)\n",
    "\n",
    "# Apply a `and` mask to keep only red pixels\n",
    "res = cv2.bitwise_and(squares, squares, mask=mask)\n",
    "\n",
    "# Display the result\n",
    "rgb = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: detection of an object in a video\n",
    "Now that we have a tool to segment pixels of a given color, we can apply the same method to track the yellow book in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the video\n",
    "vid = cv2.VideoCapture('book.mov')\n",
    "\n",
    "# Frames per second of your webcam\n",
    "FPS = vid.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Size of your frames\n",
    "frame_w = int(vid.get(3))\n",
    "frame_h = int(vid.get(4))\n",
    "\n",
    "# Create the object to save the processed video\n",
    "rec = cv2.VideoWriter('segmented_book.mov', cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), FPS, (frame_w, frame_h))\n",
    "\n",
    "# While the video lasts\n",
    "while(vid.isOpened()):\n",
    "\n",
    "    # Get the frame\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    # If no more frames, break\n",
    "    if ret == False:\n",
    "        break\n",
    "\n",
    "    # Define the color to track the yellow book \n",
    "    lower_yellow = np.array([0,80,80])\n",
    "    upper_yellow = np.array([50,255,255])\n",
    "    \n",
    "    # Threshold the image to get only the yellow book\n",
    "    mask = cv2.inRange(frame, lower_yellow, upper_yellow)\n",
    "    \n",
    "    # Apply a `and` mask to keep only the yellow book\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    # Write the result\n",
    "    rec.write(res)\n",
    "\n",
    "vid.release()\n",
    "rec.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
